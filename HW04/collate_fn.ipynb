{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.cnblogs.com/edkong/p/16256620.html\n",
    "\n",
    "collate_fn笼统的说就是用于整理数据，通常我们不需要使用.\n",
    "\n",
    "其应用的情形是：各个数据长度不一样的情况，比如第一张图片大小是28 * 28,第二张是50 * 50，这样的话就如果不自己写collate_fn，而使用默认的，就会报错。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import numpy as np\n",
    "\n",
    "# 便于结果得以复现，如何设置 seed\n",
    "myseed = 6666  # set a random seed for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(myseed)\n",
    "torch.manual_seed(myseed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(myseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9724,  0.0771,  1.3938],\n",
      "        [-0.3671, -1.2116,  0.0274],\n",
      "        [-0.7537, -1.4364, -0.2168],\n",
      "        [-0.6196, -0.2774, -0.7631]])\n",
      "tensor([0., 1., 1., 1.])\n",
      "<__main__.mydataset object at 0x000002259DF0A110>\n",
      "[(tensor([-0.9724,  0.0771,  1.3938]), tensor(0.)), (tensor([-0.3671, -1.2116,  0.0274]), tensor(1.))]\n"
     ]
    }
   ],
   "source": [
    "class mydataset(Data.Dataset):\n",
    "    def __init__(self,train_inputs,train_targets):#必须有\n",
    "        super(mydataset,self).__init__()\n",
    "        self.inputs=train_inputs\n",
    "        self.targets=train_targets\n",
    "        \n",
    "    def __getitem__(self, index):#必须重写\n",
    "        return self.inputs[index],self.targets[index]\n",
    "        \n",
    "    def __len__(self):#必须重写\n",
    "        return len(self.targets)\n",
    "\n",
    "#构造训练数据\n",
    "datax=torch.randn(4,3)#构造4个输入\n",
    "datay=torch.empty(4).random_(2)#构造4个标签\n",
    "\n",
    "#制作dataset\n",
    "dataset=mydataset(datax,datay)\n",
    "\n",
    "dataloader=Data.DataLoader(dataset,batch_size=2)\n",
    "\n",
    "print(datax)\n",
    "print(datay)\n",
    "print(dataset)\n",
    "\n",
    "batch=[dataset[0],dataset[1]]  # 所以才说和你dataset中get_item的定义有关。\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化 tensor\n",
    "\n",
    "torch.empty + random_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.1644e+09,  1.0860e-42,  3.0761e-01,  0.0000e+00])\n",
      "tensor([1., 0., 0., 1.])\n",
      "tensor([2., 0., 1., 2.])\n",
      "tensor([[5., 5., 5.],\n",
      "        [5., 5., 5.]])\n",
      "tensor([[10., 10., 10.],\n",
      "        [10., 10., 10.]])\n"
     ]
    }
   ],
   "source": [
    "# torch.empty创建的张量是未初始化的，即其值是随机的，取决于内存中的内容。因此，如果需要具有特定值的张量，应该使用其他函数进行初始化，如torch.zeros、torch.ones或torch.rand。\n",
    "# 该函数的作用是快速创建指定大小的张量，但不保证张量中的数值是有意义的，需要用户自行初始化或填充数据。\n",
    "print(torch.empty(4))\n",
    "\n",
    "# `.random_()` 方法会生成指定范围内的随机数，并将这些随机数填充到张量中，覆盖原来的数据。这样可以用来对张量进行随机初始化或随机重置。\n",
    "# 语法如下：\n",
    "# torch.Tensor.random_(from=0, to=None, *, generator=None)，- `from`：指定生成随机数的下界（包含）。- `to`：指定生成随机数的上界（不包含）。\n",
    "print(torch.empty(4).random_(2))\n",
    "print(torch.empty(4).random_(3))\n",
    "\n",
    "# 创建一个形状为(2, 3)的未初始化张量\n",
    "x = torch.empty(2, 3)\n",
    "print(x)\n",
    "\n",
    "# 对张量进行计算\n",
    "y = x + 5\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-1.4122, -0.4085, -1.8341],\n",
      "        [ 0.7787,  1.5985, -0.7262]]), tensor([0., 1.])]\n"
     ]
    }
   ],
   "source": [
    "it=iter(dataloader)\n",
    "nex=next(it)#我们展示第一个batch经过collate_fn之后的输出结果\n",
    "print(nex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4122, -0.4085, -1.8341],\n",
      "        [ 0.7787,  1.5985, -0.7262],\n",
      "        [ 0.2007, -0.8186,  0.8232],\n",
      "        [-0.3312, -1.4139, -2.2054]])\n",
      "tensor([0., 1., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "# a simple custom collate function, just to show the idea\n",
    "# `batch` is a list of tuple where first element is input tensor and the second element is corresponding label\n",
    "def my_collate(batch):\n",
    "    inputs=[data[0].tolist() for data in batch]\n",
    "    target = torch.tensor([data[1] for data in batch])\n",
    "    return [data, target]\n",
    "\n",
    "dataloader=Data.DataLoader(dataset,batch_size=2,collate_fn=my_collate)\n",
    "\n",
    "print(datax)\n",
    "print(datay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m it\u001b[38;5;241m=\u001b[39m\u001b[38;5;28miter\u001b[39m(dataloader)\n\u001b[1;32m----> 2\u001b[0m nex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mnext\u001b[39m(it)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(nex)\n",
      "File \u001b[1;32mc:\\Users\\chenbw\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\chenbw\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\chenbw\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollate_fn(data)\n",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m, in \u001b[0;36mmy_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m      4\u001b[0m inputs\u001b[38;5;241m=\u001b[39m[data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[0;32m      5\u001b[0m target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([data[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m batch])\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [data, target]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "it=iter(dataloader)\n",
    "nex=next(it)\n",
    "print(nex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
